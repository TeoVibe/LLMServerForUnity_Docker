#Model gguf location
MODEL_FILE=./models/Meta-Llama-3-8B-Instruct-Q8_0.gguf

#Server IP
HOST=0.0.0.0

#Server Port
PORT=1337

#GPU Layers
NGL=33

#Parallel Prompts
NP=4

#Chat Template
TEMPLATE="llama3 chat"

